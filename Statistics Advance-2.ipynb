{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5e10fe",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two fundamental concepts in probability and statistics that describe the distribution of a random variable.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "The PMF is used for discrete random variables. It gives the probability that a discrete random variable takes on a specific value. In other words, it maps each possible value of the random variable to its probability of occurrence.\n",
    "The PMF is denoted as P(X = x), where X is the random variable and x is a specific value it can take. The PMF must satisfy the following properties:\n",
    "\n",
    "P(X = x) ≥ 0 for all values of x.\n",
    "The sum of the probabilities for all possible values of X must be 1.\n",
    "Example:\n",
    "Let's consider a fair six-sided die. The random variable X represents the outcome of a single roll of the die, which can take values from 1 to 6.\n",
    "\n",
    "The PMF for this die would be as follows:\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "The PDF is used for continuous random variables. Unlike the PMF, which deals with discrete values, the PDF gives the probability density at each point within a continuous range of values. The probability of the random variable taking on a specific value in a continuous distribution is infinitesimally small since there are infinite possible values.\n",
    "Mathematically, the probability of the random variable falling within a certain interval [a, b] is given by the integral of the PDF over that interval: P(a ≤ X ≤ b) = ∫f(x) dx, where f(x) is the PDF.\n",
    "\n",
    "The PDF must satisfy the following properties:\n",
    "\n",
    "f(x) ≥ 0 for all values of x.\n",
    "The total area under the curve of the PDF over its entire range is equal to 1.\n",
    "Example:\n",
    "Let's consider a continuous random variable Y representing the height of individuals in a population (measured in inches). Suppose the PDF of Y is approximately normally distributed with a mean of 68 inches and a standard deviation of 3 inches.\n",
    "\n",
    "The PDF of Y (denoted as f(y)) would be given by the standard formula for the normal distribution. In this example, it is:\n",
    "\n",
    "f(y) = (1 / (3 * √(2 * π))) * exp(-(y - 68)^2 / (2 * 3^2))\n",
    "\n",
    "To find the probability that an individual's height falls within a specific range, say between 65 and 71 inches, we would integrate the PDF over that interval:\n",
    "\n",
    "P(65 ≤ Y ≤ 71) = ∫[65,71] f(y) dy\n",
    "\n",
    "Please note that the actual integral would involve using numerical techniques or standard tables since the normal distribution doesn't have a simple closed-form solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df77108",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "\n",
    "\n",
    "\n",
    "The Cumulative Density Function (CDF) is a concept used in probability and statistics that provides the cumulative probability that a random variable is less than or equal to a specific value.\n",
    "\n",
    "For discrete random variables, the CDF is the sum of the probabilities of all values less than or equal to the specified value. For continuous random variables, it is the integral of the Probability Density Function (PDF) up to that value.\n",
    "\n",
    "Mathematically, for a random variable X, the CDF is denoted as F(x) and is defined as follows:\n",
    "\n",
    "For discrete random variables:\n",
    "F(x) = P(X ≤ x) = Σ P(X = x_i), for all x_i ≤ x\n",
    "\n",
    "For continuous random variables:\n",
    "F(x) = P(X ≤ x) = ∫[a, x] f(t) dt, where f(t) is the PDF of X.\n",
    "\n",
    "Here, a represents the lower bound of the random variable's domain, and x is the specified value for which we want to find the cumulative probability.\n",
    "\n",
    "Example:\n",
    "Let's consider a fair six-sided die. The random variable X represents the outcome of a single roll of the die, which can take values from 1 to 6.\n",
    "\n",
    "To find the CDF of X, we calculate the cumulative probabilities for each value of X:\n",
    "\n",
    "F(1) = P(X ≤ 1) = P(X = 1) = 1/6\n",
    "F(2) = P(X ≤ 2) = P(X = 1) + P(X = 2) = 1/6 + 1/6 = 1/3\n",
    "F(3) = P(X ≤ 3) = P(X = 1) + P(X = 2) + P(X = 3) = 1/6 + 1/6 + 1/6 = 1/2\n",
    "F(4) = P(X ≤ 4) = P(X = 1) + P(X = 2) + P(X = 3) + P(X = 4) = 1/6 + 1/6 + 1/6 + 1/6 = 2/3\n",
    "F(5) = P(X ≤ 5) = P(X = 1) + P(X = 2) + P(X = 3) + P(X = 4) + P(X = 5) = 1/6 + 1/6 + 1/6 + 1/6 + 1/6 = 5/6\n",
    "F(6) = P(X ≤ 6) = P(X = 1) + P(X = 2) + P(X = 3) + P(X = 4) + P(X = 5) + P(X = 6) = 1/6 + 1/6 + 1/6 + 1/6 + 1/6 + 1/6 = 1\n",
    "\n",
    "So, the CDF for this fair six-sided die would be:\n",
    "\n",
    "F(x) = {\n",
    "0 for x < 1,\n",
    "1/6 for 1 ≤ x < 2,\n",
    "1/3 for 2 ≤ x < 3,\n",
    "1/2 for 3 ≤ x < 4,\n",
    "2/3 for 4 ≤ x < 5,\n",
    "5/6 for 5 ≤ x < 6,\n",
    "1 for x ≥ 6\n",
    "}\n",
    "\n",
    "Why is CDF used?\n",
    "The CDF is a crucial tool in probability and statistics for several reasons:\n",
    "\n",
    "It provides a comprehensive view of the entire distribution of a random variable by showing the probabilities for all possible values, rather than just individual points like the PMF or PDF.\n",
    "It allows us to compute probabilities for ranges of values easily. For example, to find the probability that X lies between two values a and b, we can use F(b) - F(a) for continuous random variables.\n",
    "It enables us to calculate various statistical measures such as median, quartiles, and percentiles, which are based on specific quantiles of the CDF.\n",
    "It serves as a basis for generating random numbers from a given distribution through inverse transform sampling. By using the inverse of the CDF, we can map uniformly distributed random numbers to follow the desired distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877f944",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is one of the most widely used probability distributions in statistics. It is often applied as a model in various real-world situations where certain conditions are met. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Height and Weight of Individuals: The heights and weights of a large population of individuals tend to follow approximately normal distributions.\n",
    "\n",
    "IQ Scores: Intelligence quotient (IQ) scores in a population often follow a normal distribution.\n",
    "\n",
    "Errors in Measurements: Errors in many types of measurements, such as experimental measurements or instrument readings, are often assumed to be normally distributed.\n",
    "\n",
    "Financial Markets: Returns on financial assets like stocks and bonds often exhibit behavior close to a normal distribution.\n",
    "\n",
    "Natural Phenomena: In some cases, natural phenomena, like the distribution of errors in a physical process or the distribution of certain environmental variables, can be well approximated by the normal distribution.\n",
    "\n",
    "Parameters of the Normal Distribution:\n",
    "The normal distribution is defined by two parameters: the mean (μ) and the standard deviation (σ). These parameters determine the location and spread of the distribution, respectively.\n",
    "\n",
    "Mean (μ):\n",
    "The mean of the normal distribution represents its center or the average value. It is the point around which the data cluster. If the mean is shifted to the right, the entire distribution shifts to the right, and if it is shifted to the left, the distribution shifts accordingly.\n",
    "Mathematically, the mean of the normal distribution represents the expected value of the random variable X. It is also the value where the distribution is symmetric.\n",
    "\n",
    "Standard Deviation (σ):\n",
    "The standard deviation of the normal distribution measures the spread or dispersion of the data points around the mean. A larger standard deviation indicates greater variability, while a smaller standard deviation results in data points clustering more closely around the mean.\n",
    "The standard deviation controls the width of the distribution. A higher standard deviation results in a wider and flatter curve, while a lower standard deviation leads to a narrower and taller curve.\n",
    "\n",
    "In summary, the mean determines the central location, and the standard deviation determines the spread of the normal distribution. Together, they describe the shape of the bell curve and play a crucial role in characterizing the probability distribution of the random variable X that follows the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b40281",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution.\n",
    "\n",
    "\n",
    "The normal distribution is of utmost importance in statistics and data analysis due to several reasons:\n",
    "\n",
    "Central Limit Theorem: The normal distribution is a key component of the Central Limit Theorem, which states that the sum (or average) of a large number of independent and identically distributed random variables approaches a normal distribution, regardless of the underlying distribution of the individual variables. This property allows statisticians to make inferences about a population based on a relatively small sample.\n",
    "\n",
    "Data Modeling: Many natural phenomena and real-world processes tend to exhibit normal distribution or can be well approximated by it. Using the normal distribution as a model allows us to make predictions and draw conclusions about these processes with greater accuracy.\n",
    "\n",
    "Hypothesis Testing: In inferential statistics, the normal distribution is often used as a basis for hypothesis testing. It provides a framework to assess the probability of observing certain sample statistics under the null hypothesis and helps to determine whether observed differences are statistically significant.\n",
    "\n",
    "Parameter Estimation: The normal distribution is extensively used for parameter estimation, such as estimating the mean and standard deviation of a population based on a sample.\n",
    "\n",
    "Real-Life Examples of Normal Distribution:\n",
    "\n",
    "Height of Adults: The height of adult humans follows a normal distribution in large populations. Most people tend to be close to the average height, with fewer individuals being extremely tall or short.\n",
    "\n",
    "IQ Scores: Intelligence quotient (IQ) scores of a large and diverse population also form a normal distribution. The majority of people have average IQ scores, with fewer individuals falling into the very high or very low IQ ranges.\n",
    "\n",
    "Exam Scores: In educational settings, the scores of well-designed exams tend to follow a normal distribution. The majority of students score around the class average, while fewer students score significantly higher or lower.\n",
    "\n",
    "Weight of Products: The weights of manufactured products often approximate a normal distribution. For example, the weight of bags of chips or boxes of cereal produced by a factory may follow a normal distribution.\n",
    "\n",
    "Errors in Measurements: In many scientific experiments and data collection processes, errors occur due to various factors. The distribution of these errors is often assumed to be normal.\n",
    "\n",
    "Financial Returns: The returns on investments, such as stocks, tend to follow a distribution that is close to normal, especially when considering daily or monthly returns.\n",
    "\n",
    "Environmental Data: Some environmental factors, such as daily temperature readings or rainfall measurements, can be well modeled by a normal distribution.\n",
    "\n",
    "The normal distribution's prevalence and importance in real-world scenarios make it a foundational concept in statistics, enabling scientists, researchers, and analysts to understand and work with a wide range of data and phenomena effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5255c",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (usually denoted by \"1\") and failure (usually denoted by \"0\"). It is named after the Swiss mathematician Jacob Bernoulli.\n",
    "\n",
    "The Bernoulli distribution is characterized by a single parameter, which is the probability of success (often denoted as \"p\"). The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = x) = p^x * (1 - p)^(1 - x)\n",
    "\n",
    "where X is the random variable representing the outcome (1 for success, 0 for failure) and x is either 0 or 1.\n",
    "\n",
    "Example of Bernoulli Distribution:\n",
    "A common example of the Bernoulli distribution is flipping a fair coin. If we define success as getting heads and failure as getting tails, then the probability of getting heads (success) is p = 0.5 (assuming the coin is fair).\n",
    "\n",
    "In this case, the Bernoulli distribution would be as follows:\n",
    "P(X = 0) = (1 - 0.5) = 0.5 (probability of getting tails)\n",
    "P(X = 1) = 0.5 (probability of getting heads)\n",
    "\n",
    "The Bernoulli distribution describes the probability of getting heads or tails in a single coin toss.\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "Number of Trials:\n",
    "Bernoulli Distribution: It models a single trial or experiment with two possible outcomes (success or failure).\n",
    "Binomial Distribution: It models the number of successes in a fixed number of independent Bernoulli trials (repeated experiments with the same probability of success).\n",
    "Number of Parameters:\n",
    "Bernoulli Distribution: It has a single parameter, p, which represents the probability of success in a single trial.\n",
    "Binomial Distribution: It has two parameters: n and p. \"n\" represents the number of trials or experiments, and \"p\" represents the probability of success in each individual trial.\n",
    "Type of Random Variable:\n",
    "Bernoulli Distribution: It deals with a single binary random variable (0 or 1).\n",
    "Binomial Distribution: It deals with a count of successes, which can take values from 0 to n.\n",
    "Probability Mass Function (PMF):\n",
    "Bernoulli Distribution: The PMF for Bernoulli is P(X = x) = p^x * (1 - p)^(1 - x), where x can only be 0 or 1.\n",
    "Binomial Distribution: The PMF for Binomial is given by the formula C(n, x) * p^x * (1 - p)^(n - x), where x represents the number of successes in n trials, and C(n, x) is the binomial coefficient (number of ways to choose x successes from n trials).\n",
    "In summary, the Bernoulli distribution is a special case of the binomial distribution when there is only one trial (n = 1). The binomial distribution generalizes the concept of the Bernoulli distribution to multiple independent trials with the same probability of success.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4acc9",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations.\n",
    "\n",
    "\n",
    "\n",
    "To find the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, we need to use the Z-score and the standard normal distribution table.\n",
    "\n",
    "The Z-score is a measure of how many standard deviations an observation is away from the mean. It is calculated using the formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "where:\n",
    "X = the value we want to find the probability for (in this case, 60)\n",
    "μ = the mean of the dataset (given as 50)\n",
    "σ = the standard deviation of the dataset (given as 10)\n",
    "\n",
    "Now, let's calculate the Z-score:\n",
    "\n",
    "Z = (60 - 50) / 10\n",
    "Z = 1\n",
    "\n",
    "Next, we look up the area under the standard normal distribution curve corresponding to the Z-score of 1. You can use a standard normal distribution table or a statistical calculator to find this value. The area under the curve represents the probability.\n",
    "\n",
    "From the standard normal distribution table, we find that the area corresponding to a Z-score of 1 is approximately 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from this normally distributed dataset will be greater than 60 is approximately 0.8413 or 84.13%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed78b4c",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example.\n",
    "    \n",
    "    The uniform distribution is a continuous probability distribution that models a random variable that has equal likelihood of taking any value within a specified range. In other words, all values within the range are equally likely to occur, and the probability density remains constant over that range.\n",
    "\n",
    "The probability density function (PDF) of a uniform distribution over the interval [a, b] is given by:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "\n",
    "where:\n",
    "a = the lower bound of the interval\n",
    "b = the upper bound of the interval\n",
    "\n",
    "The cumulative distribution function (CDF) for the uniform distribution is a linear function and is given by:\n",
    "\n",
    "F(x) = 0 for x < a\n",
    "F(x) = (x - a) / (b - a) for a ≤ x ≤ b\n",
    "F(x) = 1 for x ≥ b\n",
    "\n",
    "Example of Uniform Distribution:\n",
    "A classic example of the uniform distribution is rolling a fair six-sided die. In this case, the random variable X represents the outcome of a single roll, and the values it can take are 1, 2, 3, 4, 5, or 6. Each outcome has an equal chance of occurring.\n",
    "\n",
    "Let's calculate the probability density function (PDF) and cumulative distribution function (CDF) for this example:\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "The probability density function for a fair six-sided die is:\n",
    "f(x) = 1 / (6 - 1) = 1/5 for 1 ≤ x ≤ 6\n",
    "f(x) = 0 for x < 1 and x > 6\n",
    "\n",
    "Cumulative Distribution Function (CDF):\n",
    "The cumulative distribution function for a fair six-sided die is:\n",
    "F(x) = 0 for x < 1\n",
    "F(x) = (x - 1) / (6 - 1) = (x - 1) / 5 for 1 ≤ x ≤ 6\n",
    "F(x) = 1 for x ≥ 6\n",
    "\n",
    "In this example, the uniform distribution ensures that each outcome (rolling a number from 1 to 6) has an equal probability of 1/6 of occurring, as expected for a fair die. The probability of rolling any specific number within this range remains constant and uniform.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88662bc1",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score.\n",
    "    \n",
    "    he Z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations a data point is away from the mean of a dataset. It is used to standardize values from different datasets and allows comparison between data points in different distributions.\n",
    "\n",
    "The formula to calculate the Z-score of an individual data point \"X\" with mean \"μ\" and standard deviation \"σ\" is:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "The Z-score tells us how many standard deviations a data point is above or below the mean. If the Z-score is positive, the data point is above the mean, and if it is negative, the data point is below the mean. A Z-score of 0 means the data point is equal to the mean.\n",
    "\n",
    "Importance of Z-score:\n",
    "\n",
    "Standardization: The Z-score standardizes data, making it easier to compare values from different datasets with different units or scales. By converting values to a common scale (standard normal distribution with mean 0 and standard deviation 1), we can compare data points across different populations.\n",
    "\n",
    "Outlier Detection: Z-scores are useful for identifying outliers in a dataset. Data points with extreme Z-scores (far from 0) are considered outliers and may be worth investigating further as they could indicate potential errors or anomalies in the data.\n",
    "\n",
    "Probability Estimation: Z-scores are used in probability calculations based on the standard normal distribution. By converting data to Z-scores, we can find probabilities associated with specific values or ranges, which is valuable in hypothesis testing and confidence interval estimation.\n",
    "\n",
    "Data Analysis and Inference: Z-scores are often used in inferential statistics to make comparisons between sample means, test hypotheses, and draw conclusions about populations. They help to determine whether a particular value is significantly different from the mean or expected value.\n",
    "\n",
    "Data Visualization: Z-scores can be used to create standardized charts and graphs, where data from different sources are displayed on a common scale. This facilitates visual comparisons and insights.\n",
    "\n",
    "In summary, Z-scores play a fundamental role in statistical analysis by standardizing data, enabling comparisons, and providing valuable information about the position of data points relative to the mean of the distribution. They are a powerful tool in data analysis, helping researchers and analysts make more meaningful and accurate interpretations of their data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8b44b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sample means (or sums) of a large number of independent and identically distributed random variables, regardless of the underlying distribution of those variables. It states that as the sample size increases, the distribution of the sample means approaches a normal distribution, irrespective of the original population's distribution.\n",
    "\n",
    "The Central Limit Theorem can be stated as follows:\n",
    "\n",
    "Let X1, X2, ..., Xn be a random sample of size n, drawn from a population with mean μ and standard deviation σ. As n approaches infinity, the distribution of the sample means (X̄) converges to a normal distribution with a mean equal to the population mean (μ) and a standard deviation equal to the population standard deviation divided by the square root of the sample size (σ/√n).\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "Normal Approximation: The CLT allows us to approximate the distribution of sample means as a normal distribution, even if the population distribution is not normal. This is extremely powerful since the normal distribution is well understood and has several mathematical properties that make statistical analysis more feasible.\n",
    "\n",
    "Sampling Distribution: The CLT tells us about the distribution of the sample mean. It allows us to determine the spread and characteristics of the sample means as the sample size increases.\n",
    "\n",
    "Inferential Statistics: The Central Limit Theorem is crucial for inferential statistics, as it allows us to make inferences about the population parameters based on sample means. For example, we can construct confidence intervals and conduct hypothesis tests for population means using the normal distribution even when the sample size is not large.\n",
    "\n",
    "Population Distribution Irrelevance: The CLT implies that for large enough samples, we can perform statistical analyses without knowing the exact distribution of the population, as long as we have enough data points.\n",
    "\n",
    "Real-World Applications: The Central Limit Theorem is widely used in various fields, including science, engineering, economics, social sciences, and more. It underpins the validity of many statistical methods and allows researchers to analyze data and draw conclusions based on sample means even when the population distribution is unknown or complex.\n",
    "\n",
    "In summary, the Central Limit Theorem is of paramount importance in statistics as it allows us to make confident inferences and apply normal-based statistical methods to various situations, leading to more robust and accurate analyses of data, regardless of the underlying population distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba3e041",
   "metadata": {},
   "source": [
    "\n",
    "Q10: State the assumptions of the Central Limit Theorem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The Central Limit Theorem (CLT) is a powerful concept in statistics, but it relies on certain assumptions to hold true. The assumptions of the Central Limit Theorem are as follows:\n",
    "\n",
    "Random Sampling: The samples must be drawn randomly from the population of interest. Each data point in the sample should be independent of the others, and every element in the population must have an equal chance of being selected in the sample.\n",
    "\n",
    "Independence: The observations in the sample should be independent of each other. This means that the value of one observation should not influence the value of another.\n",
    "\n",
    "Identically Distributed: The random variables in the population must be identically distributed. This means that each observation in the population should be drawn from the same probability distribution.\n",
    "\n",
    "Finite Variance: The population should have a finite variance (i.e., the variance of the random variable should not be infinite). If the variance is infinite or does not exist, the CLT may not hold.\n",
    "\n",
    "Sample Size: The sample size (n) should be sufficiently large. There is no fixed threshold for the minimum sample size required, but as a general rule of thumb, a sample size greater than 30 is often considered sufficient to approximate the normal distribution.\n",
    "\n",
    "It is important to note that while the Central Limit Theorem is a powerful tool for large sample sizes, it may not hold well for small samples, especially when the underlying population distribution is highly skewed or has heavy tails.\n",
    "\n",
    "If the assumptions of the Central Limit Theorem are not met, the sample means may not follow a normal distribution, and other statistical methods, such as bootstrapping or non-parametric tests, may be more appropriate. However, in many practical situations, the CLT holds reasonably well, making it a valuable tool for statistical analysis and inference.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49dfa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
